{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1426c24a",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccf749b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3619713",
   "metadata": {},
   "source": [
    "# Download required NLTK resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15dccf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vraje\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vraje\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('default')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18cd7f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "twit_data = pd.read_csv('Twitter_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05608752",
   "metadata": {},
   "outputs": [],
   "source": [
    "twit_data = twit_data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bb9e52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  0.,  1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twit_data['category'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "373478d4",
   "metadata": {},
   "source": [
    "# Preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4751b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, label):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    text = ' '.join(filtered_words)\n",
    "    \n",
    "    # Perform stemming or lemmatization (using stemming in this example)\n",
    "    stemmer = PorterStemmer()\n",
    "    words = text.split()\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    text = ' '.join(stemmed_words)\n",
    "    \n",
    "    # Convert label to string format\n",
    "    if label == 1.0:\n",
    "        label = \"positive\"\n",
    "    elif label == 0.0:\n",
    "        label = \"neutral\"\n",
    "    else:\n",
    "        label = \"negative\"\n",
    "    \n",
    "    return text, label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f6f7185",
   "metadata": {},
   "source": [
    "# Function to train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deac45cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(data, labels):\n",
    "    # Preprocess the data\n",
    "    preprocessed_data = [preprocess_text(text, label) for text, label in zip(data, labels)]\n",
    "    preprocessed_texts, preprocessed_labels = zip(*preprocessed_data)\n",
    "    \n",
    "    # Split dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(preprocessed_texts, preprocessed_labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Vectorize the text data\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    \n",
    "    # Train the model (using LinearSVC in this example)\n",
    "    model = LinearSVC()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    return model, vectorizer, accuracy, precision, recall, f1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70c56510",
   "metadata": {},
   "source": [
    "# Function to test a new piece of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "693a0c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_new_text(text, model, vectorizer):\n",
    "    # Preprocess the text\n",
    "    preprocessed_text, _ = preprocess_text(text, None)\n",
    "    \n",
    "    # Vectorize the preprocessed text\n",
    "    text_vector = vectorizer.transform([preprocessed_text])\n",
    "    \n",
    "    # Predict the sentiment\n",
    "    sentiment = model.predict(text_vector)[0]\n",
    "    \n",
    "    return sentiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "122e7e38",
   "metadata": {},
   "source": [
    "# Train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74c58ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vectorizer, accuracy, precision, recall, f1 = train_test_model(twit_data['clean_text'], twit_data['category'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "404e2ccc",
   "metadata": {},
   "source": [
    "# Print the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d063a696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation:\n",
      "Accuracy: 84.82 %\n",
      "Precision: 84.86 %\n",
      "Recall: 84.82 %\n",
      "F1-score: 84.74 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Evaluation:\")\n",
    "print(\"Accuracy:\", round(accuracy*100, 2), \"%\")\n",
    "print(\"Precision:\", round(precision*100, 2), \"%\")\n",
    "print(\"Recall:\", round(recall*100, 2),\"%\")\n",
    "print(\"F1-score:\", round(f1*100, 2), \"%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3cf4caa",
   "metadata": {},
   "source": [
    "# Test a new piece of text and Print the sentiment result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57b6bd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "new_text = \"I'm really happy with the service.\"\n",
    "sentiment = test_new_text(new_text, model, vectorizer)\n",
    "\n",
    "print(\"Sentiment:\", sentiment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
